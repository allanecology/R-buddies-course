---
title: "Mixed model tutorial"
author: "R buddies"
date: "2023-03-29"
output: 
  html_document:
    number_sections: TRUE
    theme: sandstone
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE)
```

```{css, echo=FALSE}
.scroll-200 {
  max-height: 200px;
  overflow-y: auto;
  background-color: inherit;
}
```

```{r packages and data, class.output = "scroll-200", eval = T}
# packages
library(lme4)
library(ggplot2)
library(MuMIn) # to get the R squared of the mixed model and for model simplification (not covered here, but you could apply the function dredge() to simplify your full model)
library(arm) # to simulate data based on model estimates
library(tidyverse)

# data
# AED is the package accompanying the Book from Zuur et al.
# install.packages("remotes")
# remotes::install_github("romunov/AED")
library(AED)
data("RIKZ")

```

# Data

You can use the data introduced below or your own data. If you use your own data, you will have to adapt the code to your data.


"RIKZ" is a data set of Alain Zuur, author of the book "Mixed effects models and extensions in ecology with R" (2009). The dataset (and a few more things) are in the AED package, which you find on github. The RIKZ data set is on macrofauna species richness (response variable) measured at 9 different beaches at different distances from the sampling station to the tidal level (NAP) and at different expositions. The main interest is whether NAP and exposition affect macrofauna species richness. 

# Mixed models

Mixed effect models contain two types of effects: fixed and random effects. If we have repeated measures over time or space, we perform mixed effect models to account for the non independence between our measurements. Independence is a key assumption of linear regression. Non-independence can occur both in field and experimental studies, when we for example repeat a given experiment on different beaches.

In modelling, a parameter is fit to each level of a factor. In a fixed model, that means e.g. to each beach. Every time a model fits a parameter, we use a part of our observations (our degrees of freedom) for this. In the end, the model uses all degrees of freedom (observations) which are left to test the model. The more degrees of freedom (or observation) we use for fitting parameters, the less are left for testing the model, in other words the less power we have in the end. It therefore makes sense to think well where we want to invest our precious observations - for fitting a factor in which levels we are not really interested? Or rather in testing the model with the variables we are really interested in? Random effects are a useful way to include factors in our model, which we on one hand have to include because we feel they are important to consider, and on the other hand are not really interested in their actual effect size. E.g. in the example of beaches, we might not be interested in which of the beaches has the highest species diversity (we don't really need a model for that), but rather in the effect of exposure on species richness in general (generalised on different beaches).


### Exercise 1 

* give an example of a random effect within an experimental and within a field study
* think of fixed and random (nested or crossed?) effects in your own study

#### Solution 1

* a random effect in an experiment would be the grouping of pots in a tray, on which the same treatment is applied, and a random effect with a higher level would be the tables where you put the trays on. In this case we would have nested random effects: `(1|table/tray)`
* a random effect in a field study could be regions or populations where you sampled individuals of your study species. If species is a random factor or not depends on the number of species included in your study (include them as random factors only if you have many species)


## Random and fixed effects

**Random effects**: a way of grouping the data, which explains part of the variance but in which we are not interested in modelling. Random effects have a random number of levels (varying rule of thumb: at least 3, 4 or levels - depending on the reference) in which we are not interested in. We do not have hypotheses for random effects and do not expect an effect in a specific direction.
Random effects can be crossed (occur across the whole dataset) or nested (levels of one random effect occur only in levels of a hierarchically higher random effect, e.g if you have plots in different fields). Crossed random effects: `(1|random effect 1) + (1|random effect 2)`, nested random effects: `(1|random effect 1 / random effect 2)`. 

**Fixed effects**: effects in which we are interested in (direction and strength of effects). In other words, we are interested in the differences between the levels of a fixed effect. Fixed effects have a fixed number of levels, which are specifically chosen for a reason, and not randomly created (e.g if you are interested in the effect of different drought periods on plant performance, you specifically chose and set different levels of drought levels in your experiment). Fixed effects usually have only few levels and the levels are informative (short drought period means less stress than longer drought period).



### Exercise 2 : Plot your data (y and x variable of interest)

#### Solution 2
```{r plot data, class.output = "scroll-200", out.width= '50%'}
# check data
str(RIKZ)

# turn "Exposure" and "Beach" to factors
RIKZ$Exposure <- as.factor(RIKZ$Exposure)
RIKZ$Beach <- as.factor(RIKZ$Beach)

# plot Richness along NAP levels for different Exposures:

ggplot(RIKZ, aes(x = NAP, y = Richness)) +
  geom_point() +
  geom_smooth(method = "lm") +
  facet_wrap(~Exposure) +
  theme_classic()

# or

ggplot(RIKZ, aes(x = NAP, y = Richness, color = Exposure)) +
  geom_point() +
  geom_smooth(method = "lm") +
  theme_classic()

# include Beaches:

ggplot(RIKZ, aes(x = NAP, y = Richness, color = Beach)) +
  geom_point() +
  geom_smooth(method = "lm",
              se = F) +
  facet_wrap(~Exposure) +
  theme_classic()


```


## Likelihood method

Mixed effect models can be fitted with the maximum likelihood (ML) or the restricted maximum likelihood method (REML). ML: Underestimates the variance parameters, but is unbiased for the fixed effects. REML: Gives unbiased estimates for the variance components but is biased for the fixed effects. If you are interested in the fixed effects, use ML, if you are interested in random effects, use REML. If you are familiar with algebra, you might understand the difference between the methods -> Zuur et al. (2009) page 116.

### Exercise 3
Fit different linear mixed effect models; with one or more explanatory variables, with and without an interaction, with and without restricted maximum likelihood (REML = TRUE/FALSE) and discuss differences between the models in the model summary table.

#### Solution 3
```{r Fit linear mixed model with ML and REML, class.output = "scroll-200"}
# Maximum likelihood method
mod1 <- lmer(Richness ~ NAP * Exposure # fixed terms and their interaction
             + (1|Beach), # random term
             REML = FALSE, # likelihood method (default is REML = T)
             data = RIKZ)

mod2 <- lmer(Richness ~ NAP # fixed terms and their interaction
             + (1|Beach), # random term
             REML = FALSE, # likelihood method (default is REML = T)
             data = RIKZ)

mod3 <- lm(Richness ~ NAP, data = RIKZ) # check difference to lm (without accounting for different beaches)

summary(mod3) # model including interactions: exposure and NAP are both significant but not the interaction. NAP has a ** negative effect (estimate= -4.17)
# the model including only NAP gives a *** negative NAP effect (estimate= -2.57)
# the linear model gives a *** negative NAP effect (estimate = -2.87)

#### What might change if interactions are included?
## main effects can become less significant or non significant.
# see solution 4.3

r.squaredGLMM(mod2)
# including beach as random effect increases the R2 of the model (explained variance)


#### What might change depending on which Maximum likelihood method is used? 
# The residual variance is slightly higher if we apply the restricted maximum likelihood method.
# The models fitted with the restricted maximum likelihood method have a lower AIC

# comment on the maximum likelihood method:
# if models with different fixed effects structure are compared (this is what we normally do because we are interested in the fixed effects) we should apply ML estimation and not REML. Reason: the  REML likelihood depends on which fixed effects are in the model, and so are not comparable if the fixed effects change. REML is generally considered to give better estimates for the random effects, though, so the usual advice is to fit your best model using REML for your final inference and reporting.
# source: https://stats.stackexchange.com/questions/116770/reml-or-ml-to-compare-two-mixed-effects-models-with-differing-fixed-effects-but

ML.mod1 <- lmer(Richness ~ NAP
             + (1|Beach), 
             REML = FALSE, # maximum likelihood method (default is REML = T)
             data = RIKZ)

summary(ML.mod1) # residual variance of Beach: 9.11

ML.mod2 <- lmer(Richness ~ Exposure # other fixed effect
             + (1|Beach), 
             REML = FALSE,
             data = RIKZ)

AIC(ML.mod1, ML.mod2) # compare models
# 249 and 262

REML.mod1 <- lmer(Richness ~ NAP
             + (1|Beach), 
             REML = TRUE, # restricted maximum likelihood method
             data = RIKZ)

summary(REML.mod1) # residual variance of Beach: 9.3

REML.mod2 <- lmer(Richness ~ Exposure
             + (1|Beach), 
             REML = TRUE, # restricted maximum likelihood method
             data = RIKZ)

AIC(REML.mod1, REML.mod2) # 247 and 255


```


# Model summary table
The model summary table is explained here, with the example of mod2.
```{r}
summary(mod2)
```
* **header** : In the header, doublecheck the method you chose (ML or REML) and if this is what you aimed to do.

* **AIC and BIC** are a measure of relative model fit, penalised by number of parameters. They are used to compare models with each other, where lower AIC and BIC values indicate a better fit. With "penalised by number of parameters", we mean that a model with a good fit and a low number of parameters is preferred over a model with a slightly better fit, but a higher number of parameters (i.e. higher number of variables).

* **Residual degrees of freedom** : "df.resid" The residual degrees of freedom are the initial degrees of freedom - the number of parameter you fitted. In other words, the number of observations minus the number of factors, variables and random effect terms you have in your model. Shortly, make sure this number is not too low (not too far away from the number of observations). The nearer this number is to the number of observations, the more power you have.

* **Random effect** : For each random effect (each variable you include to the model as random), the model fits a normal distribution with mean 0 and a variance. The variance is reported in the "Variance" section. lme4 also reports the Std.Dev. = the standard deviation, which is simply the square root of the variance (not an accuracy measure of the variance itself). The residual variance is reported as well, this is the part of the variance the model can not explain with the random effects. A very low value of random effect variance and a very high value of residual variance indicates that the random effect might not be as important and you could consider excluding it. However, often it is good to keep the random effects if they are correcting for hierarchical structures in your experimental design.

  * **Number of obs** : shows you on how many observations the model was fit. It is important to check if this number corresponds to the number of rows in your dataset. If it does not, check if you have NA values which were automatically excluded.
  
```{r}
nrow(RIKZ) == 45
```

* **Fixed effects** : this part is similar to the linear model output :
  * For numeric variables, you get an estimate of the slope and a standard error, as well as a separate estimate of the intercept.
  * For factors, you get an estimate of each level of the factor. The first level of the factor is reported as "Intercept", the second is shown with the name of your factor and the level.

* Correlations of fixed effects : You get a full correlation matrix of all variables and factor levels of your dataset.

### Exercises 4
Interpreting the summary output

```{r}
# 4.1: Compare the summary output of the two models; what changes? Which one would you prefer and why?
mod_ex4a <- lmer(Richness ~ NAP + (1|Exposure),
                 REML = FALSE, data = RIKZ)

mod_ex4b <- lmer(Richness ~ NAP + (1|Beach),
                 REML = FALSE, data = RIKZ)


# 4.2: What happens with the effect of NAP in the following model and why? 

mod_ex4c <- lmer(Richness ~ NAP + (1|Beach),
                 REML = FALSE, 
                 data = RIKZ %>% group_by(Beach) %>% sample_frac(size = 1-0.59))


# 4.3: What happens with the effect of NAP depending on how NAP is fitted? 
mod_ex4d <- lmer(Richness ~ NAP * Exposure + (1|Beach),
                 REML = TRUE, data = RIKZ)

mod_ex4e <- lmer(Richness ~ NAP + Exposure + (1|Beach),
                 REML = FALSE, data = RIKZ)


# 4.4. Use the model used in Exercise 4.1 (mod_ex4b) using NAP as a fixed, and Beach as a random term. The mixed effect model with 
# random intercept, which we are using here, models the intercept from each beach as "realisations" (=samples) from a normal distribution
# around the fixed intercept. In other words, we have a "global" intercept (a global linear model), and around this, we have the intercepts (the lines) of the individual beaches. The Intercept of all the individual lines lay around the "global" intercept, and their distance is 
# given by the random intercept variation.
# Try to draw or plot the "global" model (fixed effect) and the intercept of all nine beaches around this global model.
mod_ex4b <- lmer(Richness ~ NAP + (1|Beach),
                 REML = FALSE, 
                 data = RIKZ)

```


#### Solutions 4
```{r}
# 4.1: Compare the summary output of the two models; what changes? Which one would you prefer and why?
mod_ex4a <- lmer(Richness ~ NAP + (1|Exposure),
                 REML = FALSE, data = RIKZ)

mod_ex4b <- lmer(Richness ~ NAP + (1|Beach),
                 REML = FALSE, data = RIKZ)

# 4.1 Solution: There is no big difference in the estimate of how NAP affects Richness (-2.7) and also not in the significance level. Also, the amount of variance explained by the random effect is similar. Residuals are +/- normally distributed independent of whether we include Beach or Exposure as random effect. However, I would prefer the model including Beach as random effect because we are not interested in the effect of beach, i.e there is no reason why we could expect a certain effect of beach in a certain direction on Richness. There are thousands of beaches and in this study we have a random sample of beaches, whereas for exposure we have pre-defined levels in which we are interested in. 

# 4.2: What happens with the effect of NAP in the following model and why? 

mod_ex4c <- lmer(Richness ~ NAP + (1|Beach),
                 REML = FALSE, 
                 data = RIKZ %>% group_by(Beach) %>% sample_frac(size = 1-0.59))

# 4.2 Solution: the effect of NAP on Richness becomes less significant because we have a reduction in our degrees of freedom and hence lose statistical power.

# 4.3: What happens with the effect of NAP depending on how NAP is fitted? 
mod_ex4d <- lmer(Richness ~ NAP * Exposure + (1|Beach),
                 REML = TRUE, data = RIKZ)

mod_ex4e <- lmer(Richness ~ NAP + Exposure + (1|Beach),
                 REML = FALSE, data = RIKZ)

# 4.3 Solution: If NAP is fitted without the interaction with Exposure, the slope of the effect decreased but the significance level increases. This model calculates the variance explained by NAP and by Exposure separately, whereas the first model takes into account that depending on the Exposure, the slope of the NAP effect is different. After accounting for the effect of the combinations of NAP and Exposure, a main effect of NAP is calculated. In general, there are several reasons why the main effect often becomes less significant if interactions are included: first, each of the interactions is an additional parameter that the model needs to evaluate, reducing the residual degrees of freedom. Second, the effect of a parameter might be different depending on the level of the second parameter (in different directions), with what the main effect becomes less significant. The main effect is then estimated as the average of the effects of the single levels of the parameter (which can be in different directions).
# in general, I would always look at the raw data to decide whether or not to include an interaction.


# 4.4. Use the model used in Exercise 4.1 (mod_ex4b) using NAP as a fixed, and Beach as a random term. The mixed effect model with 
# random intercept, which we are using here, models the intercept from each beach as "realisations" (=samples) from a normal distribution
# around the fixed intercept. In other words, we have a "global" intercept (a global linear model), and around this, we have the intercepts (the lines) of the individual beaches. The Intercept of all the individual lines lay around the "global" intercept, and their distance is 
# given by the random intercept variation.
# Try to draw or plot the "global" model (fixed effect) and the intercept of all nine beaches around this global model.
mod_ex4b <- lmer(Richness ~ NAP + (1|Beach),
                 REML = FALSE, 
                 data = RIKZ)
summary(mod_ex4b) # the global intercept is 6.5844
#                   the variance around the intercept is 7.51, that means the standard deviation is the 
#                     square root of the variance, which is sqrt(7.51) = 2.74
# We can get the estimates of each random effect with the coef function
coef(mod_ex4b)
# Plotting
plot(RIKZ$NAP, fitted(mod_ex4b))
abline(coef = c(6.58, -2.575), lwd = 3) # reading intercept and slope from the summary output
for(i in 1:length(unique(RIKZ$Beach))){
  abline(coef = coef(mod_ex4b)$Beach[i , ])
}
# global model = the population model in bold
# the individual beach models in non-bold

# Plotting : only plot the intercepts, and the normal distribution around them.
hist(coef(mod_ex4b)$Beach[, 1])
x <- seq(-20, 20, length=100)
y <- dnorm(x, mean = 6.5844, sd = 2.740)
plot(x, y, type = "l", lwd = 2, ylab = "Density", xlab = "Richness Intercept")
abline(v = 6.5844, col = "red", lwd = 2)
for(i in 1:length(unique(RIKZ$Beach))){
  abline(v = coef(mod_ex4b)$Beach[i , 1], col = "gray")
}
# Source : Exercises adapted from Zuur et al. 2009, Chapter 5 p. 108
```



### Exercise 5.1

Fit a mixed effect model on a subset of the RIKZ dataset, where you only include the observations with Exposure 10. Use Exposure as fixed effect, and Beach as random effect.

#### Solution 5
```{r, error=TRUE}
# Solution
mod_ex1 <- lmer(Richness ~ Exposure + (1 | Beach), REML = F, data = RIKZ[which(RIKZ$Exposure == 10), ])
# The function throws an error, because there is only one level of the factor. 
```

### Exercise 5.1.b
Explain why the model threw an error.

#### Solution 5.1.b
```{r}
# Solution
# because all levels of "Exposure" are the same, we do not need "Exposure" as factor in our model if all observations are from the same exposure.
mod_ex1b <- lmer(Richness ~ (1 | Beach), REML = F, data = RIKZ[which(RIKZ$Exposure == 10), ])
summary(mod_ex1b)
```

### Exercise 5.2
(1.2) Fit a mixed effect model on a subset of the RIKZ dataset, where you only include the observations from Beach 6. Use Exposure as fixed effect, and Beach as random effect.

#### Solution 5.2
```{r, error=TRUE}
# Solution
mod_ex2 <- lmer(Richness ~ (1 | Beach), REML = F, data = RIKZ[which(RIKZ$Beach == 6), ])
# again, we need more than 1 level in the random effect.
```

### Exercise 5.2.b
Fit a mixed effect model on a subset of the RIKZ dataset, where you only include the observations from Beach 6 and 1. Use Exposure as fixed effect, and Beach as random effect. Try to explain why you see what you see.

#### Solution 5.2.b
```{r}
# Solution
mod_ex2 <- lmer(Richness ~ Exposure + (1 | Beach), REML = F, data = RIKZ[which(RIKZ$Beach %in% c(1,6)), ])
help('isSingular')
# There is a minimum amount of variance we need to fit a model at all. In our example, the variables beach and exposure explain exactly the same :
table(RIKZ[which(RIKZ$Beach %in% c(1,6)), c("Exposure", "Beach")])
# See that for most beaches and most exposures, we do not have a single observation
# In fact, all beaches with exposure 11 are from beach 6, and all beaches with exposure 10 are from beach 1.
table(RIKZ[, c("Exposure", "Beach")])
# A given beach is at a fixed exposure, we have some variance only because various beaches were measured per exposure level.
```








# Model validation
We validate our model based on the model assumptions that the **residuals are identically and independently distributed**:

* independent residuals: do not correlate with other variables, are not grouped and are not autocorrelated (spatially or temporally)
* identically distributed residuals: all residuals come from the same distribution; the normal distribution assumes homogeneity of variance (no pattern in residuals) and the mean of the residuals across all predictors should be zero

Further, we can assess the general model fit by comparing the fitted (predicted) and observed values. (First step in below code.)

### Exercise 6
which of your models is the best model based on visual validation? How could you improve your model? What else can we consider when we validate our model?

#### Solution 6
```{r plot residuals against fitted, class.output = "scroll-200"}
# Assessing global model fit
plot(fitted(mod1), RIKZ$Richness)
abline(0, 1)

# Assessing model assumptions
# 1. Homogeneity of variance: 
  # residuals vs fitted values
par(mfrow=c(2,2), mar=c(4,4,2,1), mgp=c(2.2,0.8,0))
scatter.smooth(fitted(mod1), resid(mod1)); abline(h=0, lty=2)
mtext("Tukey-Anscombe Plot", 3, line=0.8, cex=0.8)#,family="A")

  # residual variance against fitted
scatter.smooth(fitted(mod1), sqrt(abs(resid(mod1))))

# 2. Normality of residuals: qq of residuals
qqnorm(resid(mod1), main="Normal qq-plot, residuals", cex.main=0.8)
qqline(resid(mod1))
  
  # normality of random effects
qqnorm(ranef(mod1)$Beach[,1], main="Normal qq-plot, random effects", cex.main=0.8)
qqline(ranef(mod1)$Beach[,1]) 
# Interpretation : bad model.. random effects explain zero variance.

# example with mod2, where variance of random effect is not 0
qqnorm(ranef(mod2)$Beach[,1], main="Normal qq-plot, random effects", cex.main=0.8)
qqline(ranef(mod2)$Beach[,1])
```



## Model validation with simulation
```{r compare model simulated data with raw data, class.output = "scroll-200"}
# simulate 1000 random samples with your model (based on model estimates)
nsim=1000 
bsim=sim(mod1,n.sim=nsim)
bsim

fitmat=matrix(ncol=nsim,nrow=nrow(RIKZ)) # calculate a matrix out of these simulations
yrep=matrix(ncol=nsim,nrow=nrow(RIKZ))

newdat=expand.grid(NAP = seq(range(RIKZ$NAP)[1],range(RIKZ$NAP)[2], by = 0.01), Exposure=levels(RIKZ$Exposure))

# create a new data frame
Xmat=model.matrix(~ NAP * Exposure, data=newdat)  # use exactly the same formula as for the fixed-effect part in the model specification

# with credible intervals
fitmat=matrix(ncol=nsim, nrow=nrow(newdat)) # fitmap are estimates of the mean
for(i in 1:nsim) fitmat[,i]=Xmat %*% bsim@fixef[i,] # fitted values
newdat$lower=apply(fitmat, 1, quantile, prob=0.025) # credible interval lower bound
newdat$upper=apply(fitmat, 1, quantile, prob=0.975) # credible interval upper
newdat$fit=Xmat %*% fixef(mod1)

# check if simulated data fits to raw data
for(i in 1:nsim){
  fitmat[,i]=Xmat %*% bsim@fixef[i,]
  yrep[,i]=rnorm(n=nrow(RIKZ), mean=fitmat[,i], sd = sd(fitmat[,i]))
}
par(mfrow=c(3,3)) # fenster reihen/spalten
random=sample(1:nsim,9) # nbr of simulations - er nimmt einfach 9 simulationen aus den 1000 die er fÃ¼r newdat gerechnet hat
for (i in 1:9) {
  if(i==5) {
    hist(RIKZ$NAP)
  } else hist(yrep[,random[i]])
}


```


# References

Zuur, A. F., Ieno, E. N., Walker, N. J., Saveliev, A. A., & Smith, G. M. (2009). Mixed effects models and extensions in ecology with R (Vol. 574, p. 574). New York: springer.

Dr. Eva Malecore; course on mixed effect models, IPS Bern